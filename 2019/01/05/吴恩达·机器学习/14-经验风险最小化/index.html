<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    
    <title>经验风险最小化 | Jiacheng Pan&#39;s Wiki</title>
    
    
        <meta name="keywords" content="机器学习,ERM,经验风险">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="就线性分类模型而言，可以将其表示为： \[ h_\theta(x)=g(\theta^Tx), \\\ g(z) = 1\lbrace z \geq 0 \rbrace \] 其中，训练集表示为： \[ S=\lbrace (x^{(i)}, y^{(i)}) \rbrace _ {i = 1} ^ m, (x^{(i)}, y^{(i)}) \sim {\cal D} \] 这里假设了训练数据都">
<meta name="keywords" content="机器学习,ERM,经验风险">
<meta property="og:type" content="article">
<meta property="og:title" content="经验风险最小化">
<meta property="og:url" content="https://jiacheng-pan.github.io/wiki/2019/01/05/吴恩达·机器学习/14-经验风险最小化/index.html">
<meta property="og:site_name" content="Jiacheng Pan&#39;s Wiki">
<meta property="og:description" content="就线性分类模型而言，可以将其表示为： \[ h_\theta(x)=g(\theta^Tx), \\\ g(z) = 1\lbrace z \geq 0 \rbrace \] 其中，训练集表示为： \[ S=\lbrace (x^{(i)}, y^{(i)}) \rbrace _ {i = 1} ^ m, (x^{(i)}, y^{(i)}) \sim {\cal D} \] 这里假设了训练数据都">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://jackie-image.oss-cn-hangzhou.aliyuncs.com/19-01-06/image-20190106143941030.png">
<meta property="og:image" content="http://jackie-image.oss-cn-hangzhou.aliyuncs.com/19-01-06/image-20190106154201189.png">
<meta property="og:updated_time" content="2019-01-20T14:21:01.717Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="经验风险最小化">
<meta name="twitter:description" content="就线性分类模型而言，可以将其表示为： \[ h_\theta(x)=g(\theta^Tx), \\\ g(z) = 1\lbrace z \geq 0 \rbrace \] 其中，训练集表示为： \[ S=\lbrace (x^{(i)}, y^{(i)}) \rbrace _ {i = 1} ^ m, (x^{(i)}, y^{(i)}) \sim {\cal D} \] 这里假设了训练数据都">
<meta name="twitter:image" content="http://jackie-image.oss-cn-hangzhou.aliyuncs.com/19-01-06/image-20190106143941030.png">
    

    
        <link rel="alternate" href="/atom.xml" title="Jiacheng Pan&#39;s Wiki" type="application/atom+xml">
    

    
        <link rel="icon" href="/wiki/favicon.ico">
    

    <link rel="stylesheet" href="/wiki/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/wiki/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/wiki/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/wiki/css/style.css">
    <script src="/wiki/libs/jquery/2.1.3/jquery.min.js"></script>
    <script src="/wiki/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>
    
    
        <link rel="stylesheet" href="/wiki/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/wiki/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
</head>
</html>
<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/wiki/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Jiacheng Pan&#39;s Wiki</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="https://jiacheng-pan.github.io/">首页</a>
                
                    <a class="main-nav-link" href="/wiki/archives">归档</a>
                
                    <a class="main-nav-link" href="/wiki/categories">分类</a>
                
                    <a class="main-nav-link" href="/wiki/tags">标签</a>
                
                    <a class="main-nav-link" href="/wiki/about">关于</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search">
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/wiki/',
        CONTENT_URL: '/wiki/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/wiki/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="https://jiacheng-pan.github.io/">首页</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/wiki/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search">
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    <div class="widget-wrap" id="categories">
        <h3 class="widget-title">
            <span>categories</span>
            &nbsp;
            <a id="allExpand" href="#">
                <i class="fa fa-angle-double-down fa-2x"></i>
            </a>
        </h3>
        
        
        
         <ul class="unstyled" id="tree"> 
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            GraphKnowledge
                        </a>
                         <ul class="unstyled" id="tree">  <li class="file"><a href="/wiki/2019/01/18/GraphKnowledge/Home/">1: Introduction</a></li>  <li class="file"><a href="/wiki/2019/01/18/GraphKnowledge/节点相关的概念/">2: 节点相关的概念</a></li>  <li class="file"><a href="/wiki/2019/01/18/GraphKnowledge/结构相关的概念/">3: 结构相关的概念</a></li>  <li class="file"><a href="/wiki/2019/01/18/GraphKnowledge/链接相关的概念/">4: 链接相关的概念</a></li>  <li class="file"><a href="/wiki/2019/01/18/GraphKnowledge/矩阵相关的概念/">5: 矩阵相关的概念</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder"></i>
                            &nbsp;
                            webgl
                        </a>
                         <ul class="unstyled" id="tree">  <li class="file"><a href="/wiki/2019/06/06/webGL/WebGL-BatchDraw代码阅读+理解/">1: WebGL-BatchDraw代码阅读+理解</a></li>  <li class="file"><a href="/wiki/2019/06/06/webGL/WebGL学习笔记/">2: WebGL学习笔记</a></li>  </ul> 
                    </li> 
                    
                    <li class="directory open">
                        <a href="#" data-role="directory">
                            <i class="fa fa-folder-open"></i>
                            &nbsp;
                            吴恩达·机器学习
                        </a>
                         <ul class="unstyled" id="tree">  <li class="file"><a href="/wiki/2018/06/03/吴恩达·机器学习/01-监督学习&梯度下降法/">1: 监督学习&梯度下降法</a></li>  <li class="file"><a href="/wiki/2018/06/03/吴恩达·机器学习/02-线性回归/">2: 线性回归</a></li>  <li class="file"><a href="/wiki/2018/06/04/吴恩达·机器学习/03-过拟合&局部加权回归/">3: 过拟合&局部加权回归</a></li>  <li class="file"><a href="/wiki/2018/06/05/吴恩达·机器学习/04-线性模型的概率解释/">4: 线性模型的概率解释</a></li>  <li class="file"><a href="/wiki/2018/06/05/吴恩达·机器学习/05-二分类问题/">5: 二分类问题</a></li>  <li class="file"><a href="/wiki/2018/06/07/吴恩达·机器学习/06-牛顿法/">6: 牛顿法</a></li>  <li class="file"><a href="/wiki/2018/06/09/吴恩达·机器学习/07-广义线性模型/">7: 广义线性模型</a></li>  <li class="file"><a href="/wiki/2018/06/29/吴恩达·机器学习/08-生成学习算法的概念/">8: 生成学习算法的概念</a></li>  <li class="file"><a href="/wiki/2018/06/29/吴恩达·机器学习/09-生成学习算法的例子/">9: 生成学习算法的例子</a></li>  <li class="file"><a href="/wiki/2018/07/02/吴恩达·机器学习/10-SVM（一）概念/">10: SVM（一）概念</a></li>  <li class="file"><a href="/wiki/2018/07/03/吴恩达·机器学习/11-SVM（二）最优间隔分类器/">11: SVM（二）最优间隔分类器</a></li>  <li class="file"><a href="/wiki/2018/07/22/吴恩达·机器学习/12-SVM（三）核函数/">12: SVM（三）核函数</a></li>  <li class="file"><a href="/wiki/2018/07/25/吴恩达·机器学习/13-SVM（四）非线性决策边界/">13: SVM（四）非线性决策边界</a></li>  <li class="file active"><a href="/wiki/2019/01/05/吴恩达·机器学习/14-经验风险最小化/">14: 经验风险最小化</a></li>  <li class="file"><a href="/wiki/2019/01/10/吴恩达·机器学习/15-Vapnik-Chervonenkis Dimension/">15: Vapnik–Chervonenkis dimension</a></li>  <li class="file"><a href="/wiki/2019/01/18/吴恩达·机器学习/16-模型选择和特征选择/">16: 模型选择和特征选择</a></li>  </ul> 
                    </li> 
                     </ul> 
    </div>
    <script>
        $(document).ready(function() {
            var iconFolderOpenClass  = 'fa-folder-open';
            var iconFolderCloseClass = 'fa-folder';
            var iconAllExpandClass = 'fa-angle-double-down';
            var iconAllPackClass = 'fa-angle-double-up';
            // Handle directory-tree expansion:
            // 左键单独展开目录
            $(document).on('click', '#categories a[data-role="directory"]', function (event) {
                event.preventDefault();

                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var subtree = $(this).siblings('ul');
                icon.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if (expanded) {
                    if (typeof subtree != 'undefined') {
                        subtree.slideUp({ duration: 100 });
                    }
                    icon.addClass(iconFolderCloseClass);
                } else {
                    if (typeof subtree != 'undefined') {
                        subtree.slideDown({ duration: 100 });
                    }
                    icon.addClass(iconFolderOpenClass);
                }
            });
            // 右键展开下属所有目录
            $('#categories a[data-role="directory"]').bind("contextmenu", function(event){
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconFolderOpenClass);
                var listNode = $(this).siblings('ul');
                var subtrees = $.merge(listNode.find('li ul'), listNode);
                var icons = $.merge(listNode.find('.fa'), icon);
                icons.removeClass(iconFolderOpenClass).removeClass(iconFolderCloseClass);
                if(expanded) {
                    subtrees.slideUp({ duration: 100 });
                    icons.addClass(iconFolderCloseClass);
                } else {
                    subtrees.slideDown({ duration: 100 });
                    icons.addClass(iconFolderOpenClass);
                }
            })
            // 展开关闭所有目录按钮
            $(document).on('click', '#allExpand', function (event) {
                event.preventDefault();
                
                var icon = $(this).children('.fa');
                var expanded = icon.hasClass(iconAllExpandClass);
                icon.removeClass(iconAllExpandClass).removeClass(iconAllPackClass);
                if(expanded) {
                    $('#sidebar .fa.fa-folder').removeClass('fa-folder').addClass('fa-folder-open')
                    $('#categories li ul').slideDown({ duration: 100 });
                    icon.addClass(iconAllPackClass);
                } else {
                    $('#sidebar .fa.fa-folder-open').removeClass('fa-folder-open').addClass('fa-folder')
                    $('#categories li ul').slideUp({ duration: 100 });
                    icon.addClass(iconAllExpandClass);
                }
            });  
        });
    </script>

    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-吴恩达·机器学习/14-经验风险最小化" class="article article-type-post" itemscope="" itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/wiki/categories/吴恩达·机器学习/">吴恩达·机器学习</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/wiki/tags/ERM/">ERM</a>, <a class="tag-link" href="/wiki/tags/机器学习/">机器学习</a>, <a class="tag-link" href="/wiki/tags/经验风险/">经验风险</a>
    </div>

                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/wiki/2019/01/05/吴恩达·机器学习/14-经验风险最小化/">
            <time datetime="2019-01-05T05:53:00.000Z" itemprop="datePublished">2019-01-05</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a href="https://github.com/zthxxx/Wiki-site/raw/writing/source/_posts/吴恩达·机器学习/14-经验风险最小化.md"> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a href="https://github.com/zthxxx/Wiki-site/edit/writing/source/_posts/吴恩达·机器学习/14-经验风险最小化.md"> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a href="https://github.com/zthxxx/Wiki-site/commits/writing/source/_posts/吴恩达·机器学习/14-经验风险最小化.md"> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            经验风险最小化
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
        
        
            <p>就线性分类模型而言，可以将其表示为： <span class="math display">\[
h_\theta(x)=g(\theta^Tx), \\\
g(z) = 1\lbrace z \geq 0 \rbrace
\]</span> 其中，训练集表示为： <span class="math display">\[
S=\lbrace (x^{(i)}, y^{(i)}) \rbrace _ {i = 1} ^ m, (x^{(i)}, y^{(i)}) \sim {\cal D}
\]</span> 这里假设了训练数据都是独立同分布的。</p>
<p>那么，我们认为，这个线性分类器的<strong>训练误差</strong>就可以表示为它分类错误的样本比例： <span class="math display">\[
{\hat{\varepsilon}}(h_\theta) = {\hat{\varepsilon}}_s(h_\theta) = \frac{1}{m}\sum_{i=1}^m1\lbrace h_\theta (x^{(i)}) \neq y^{(i)} \rbrace
\]</span> 在这里，我们把训练误差也称为<strong>风险</strong>（risk），由此我们导出了经验风险最小化。</p>
<h3 id="经验风险最小化">经验风险最小化</h3>
<h3 id="empirical-risk-minimizationerm">Empirical Risk Minimization，ERM</h3>
<p>经验风险最小化，最终导出一组参数，能够使得训练误差最小： <span class="math display">\[
{\hat{\theta}} = \arg \min {\hat{\varepsilon}}_s(h_\theta)
\]</span></p>
<p>我们再定义一个假设类<span class="math inline">\({\cal{H}} = \lbrace h_\theta, \theta \in {\Bbb R}^{n+1} \rbrace\)</span>，它是所有假设的集合。在线性分类中，也就是所有线性分类器的集合。</p>
<p>那么，我们可以重新定义一次ERM： <span class="math display">\[
{\hat h} = \mathop{\arg \min}_{h \in {\cal H}} {\hat \varepsilon}(h)
\]</span> 对上述公式的直观理解就是：从假设类中选取一个假设，使得训练误差最小。我们这里用了<span class="math inline">\(\hat{h}\)</span>表示估计，因为毕竟不可能得到最好的假设，只能得到对这个最好的假设的估计。</p>
<p>但这仍然不是目标，我们的目标是使得<strong>泛化误差 Generalization Error</strong>最小化，也即新的数据集上分类错误的概率： <span class="math display">\[
\varepsilon(h)=P_{(x,y) \sim {\cal D}}(h(x) \neq y)
\]</span> 接下去，为了证明：</p>
<ul>
<li><p>（1）<span class="math inline">\({\hat \varepsilon} \approx \varepsilon\)</span>，训练误差近似于泛化误差（理解为，泛化误差和训练误差之间的差异存在上界）</p></li>
<li><p>（2）ERM输出的泛化误差<span class="math inline">\(\varepsilon({\hat h})\)</span>存在上界；</p></li>
</ul>
<p>我们引出两个引理：</p>
<ul>
<li><p>联合界引理（Union Bound）</p>
<blockquote>
<p><span class="math inline">\(A_1, A_2, \ldots , A_k\)</span>是k个事件，他们之间并不一定是独立分布的，有： <span class="math display">\[
P(A_1 \cup \ldots \cup A_k) \leq P(A_1) + \dots + P(A_k)
\]</span></p>
</blockquote></li>
<li><p>Hoeffding不等式（Hoeffding Inequality）</p>
<blockquote>
<p><span class="math inline">\(z_1, \ldots z_m\)</span>是m个iid（independent and identically distribution，独立同分布），他们都服从伯努利分布，<span class="math inline">\(P(z_i=1) = \phi\)</span>，那么对<span class="math inline">\(\phi\)</span>的估计： <span class="math display">\[
{\hat \phi} = \frac{1}{m}\sum_{i=1}^m z_i
\]</span> 于是，给定<span class="math inline">\(\gamma &gt; 0\)</span>，有： <span class="math display">\[
P(|{\hat{\phi}} - \phi| &gt; \gamma) \leq 2 exp(-2\gamma^2m)
\]</span></p>
</blockquote>
<p>Hoeffding不等式的直观解释就是，下图中的阴影面积，会有上界。</p>
<figure>
<img src="http://jackie-image.oss-cn-hangzhou.aliyuncs.com/19-01-06/image-20190106143941030.png" alt="image-20190106143941030"><figcaption>image-20190106143941030</figcaption>
</figure></li>
</ul>
<h3 id="一致收敛">一致收敛</h3>
<h3 id="uniform-conversions">Uniform Conversions</h3>
<p>对于某个<span class="math inline">\(h_j \in \cal{H}\)</span>，我们定义<span class="math inline">\(z_i = 1 \lbrace h_j(x^{(i)}) \neq y^{(i)}\rbrace \in \lbrace{}\)</span>为第i个样本被分类错误的指示函数的值，对于logistic而言，它服从伯努利分布。</p>
<p>那么：</p>
<ol type="1">
<li>泛化误差：<span class="math inline">\(P(z_i=1) = \varepsilon(h_j)\)</span></li>
<li>训练误差：<span class="math inline">\({\hat{\varepsilon}}(h_j) = \frac{1}{m}\sum_{i=1}^m z_i\)</span></li>
</ol>
<p>根据Hoeffding不等式，我们能够得到： <span class="math display">\[
P(|{\hat{\varepsilon}}(h_j) - \varepsilon(h_j)| &gt; \gamma) \leq 2e^{-2\gamma^2m}
\]</span> 接着，我们定义训练误差和泛化误差之间的差大于<span class="math inline">\(\gamma\)</span>（<span class="math inline">\(|{\hat{\varepsilon}}(h_j) - \varepsilon(h_j)| &gt; \gamma\)</span>）为事件<span class="math inline">\(A_j\)</span>，根据以上结论，我们可知： <span class="math display">\[
P(A_j) \leq 2e^{-2\gamma^2m}
\]</span> 那么根据联合界引理： <span class="math display">\[
\begin{array}{l}
&amp; P(\exists h_j \in H, |{\hat{\varepsilon}}(h_j) - \varepsilon(h_j)| &gt; \gamma) \\\
= &amp; P(A_1 \cup A_2 \cup \ldots \cup A_k) \\\
\leq &amp; \sum_{i=1}^k P(A_i) \\\
\leq &amp; \sum_{i=1}^k 2e^{-2\gamma^2m} \\\
= &amp; 2ke^{-2\gamma^2m}
\end{array}
\]</span> 可以表述为：存在<span class="math inline">\(h_j\)</span>使<span class="math inline">\(|{\hat{\varepsilon}}(h_j) - \varepsilon(h_j)| &gt; \gamma\)</span>的概率<span class="math inline">\(\leq 2ke^{-2\gamma^2m}\)</span>。</p>
<p>等价于：不存在<span class="math inline">\(h_j\)</span>使<span class="math inline">\(|{\hat{\varepsilon}}(h_j) - \varepsilon(h_j)| &gt; \gamma\)</span>的概率<span class="math inline">\(\geq 1 - 2ke^{-2\gamma^2m}\)</span>。</p>
<p>等价于：<span class="math inline">\(\cal H\)</span>中任意的<span class="math inline">\(h_j\)</span>使得<span class="math inline">\(|{\hat{\varepsilon}}(h_j) - \varepsilon(h_j)| \leq \gamma\)</span>的概率<span class="math inline">\(\geq 1 - 2ke^{-2\gamma^2m}\)</span>。</p>
<p>我们将上面这个结论称之为<strong>一致收敛 Uniform Conversions</strong>，也就是说事实上，所有的假设，训练误差和泛化误差之间都存在上界。</p>
<h3 id="样本复杂度误差界以及偏差方差权衡">样本复杂度，误差界以及偏差方差权衡</h3>
<p>上面的结论，我们可以引出以下的一些推论：</p>
<h4 id="样本复杂度-sample-complexity">样本复杂度 Sample Complexity</h4>
<p>给定<span class="math inline">\(\gamma, \delta\)</span>，需要多大的训练集合（<span class="math inline">\(m\)</span>）？其中<span class="math inline">\(\delta\)</span>指的是泛化误差和训练误差之差大于<span class="math inline">\(\gamma\)</span>的概率。</p>
<p>我们知道，<span class="math inline">\(\delta \leq 2ke^{-2\gamma^2m}\)</span>，可求解： <span class="math display">\[
m \geq \frac{1}{2 \gamma ^ 2} log(\frac{2k}{\delta})
\]</span> 这个，也被称为样本复杂度（类似于时间复杂度），指的是，只要满足上面这个条件，任意<span class="math inline">\(h \in \cal H\)</span>，都能得到<span class="math inline">\(|{\hat{\varepsilon}}(h_j) - \varepsilon(h_j)| \leq \gamma\)</span></p>
<h4 id="误差界-error-bound">误差界 Error Bound</h4>
<p>给定<span class="math inline">\(\delta, m\)</span>时，我们会得到多大的误差上界<span class="math inline">\(\gamma\)</span>。</p>
<p>经过求解可以得到： <span class="math display">\[
P(\forall h \in {\cal H}, |{\hat{\varepsilon}}(h_j) - \varepsilon(h_j)| \leq \sqrt{\frac{1}{2m}log(\frac{2k}{\delta})}) \geq 1 - \delta
\]</span> 也就是误差上界是：<span class="math inline">\(\gamma = \sqrt{\frac{1}{2m}log(\frac{2k}{\delta})}\)</span>。</p>
<h3 id="偏差方差权衡-bias-variance-tradeoff">偏差方差权衡 Bias Variance Tradeoff</h3>
<p>我们定义： <span class="math display">\[
\begin{align}
{\hat h} &amp;= \mathop{\arg \min}_{h \in \cal H} {\hat \varepsilon}(h) \text{, 使得训练误差最小的h}
&amp;\tag{1} \\\
h^\ast &amp;= \mathop{\arg \min}_{h \in \cal H} \varepsilon(h) \text{, 使得泛化误差最小的h} \tag{2}
\end{align}
\]</span> 假如： <span class="math display">\[
\forall h \in {\cal H}, |{\hat{\varepsilon}}(h_j) - \varepsilon(h_j)| \leq \gamma \tag{3}
\]</span></p>
<p>那么： <span class="math display">\[
\begin{align}
\varepsilon(\hat h) &amp;\leq {\hat \varepsilon}({\hat h}) + \gamma, &amp;\text{derived from (3)}\\\
&amp;\leq {\hat \varepsilon}(h^\ast) + \gamma, &amp;\text{derived from (1)}\\\
&amp;\leq {\varepsilon(h^\ast)} + \gamma + \gamma, &amp;\text{ derived from (3)}
\end{align}
\]</span> 于是，我们得到如下定理：</p>
<p>给定大小为<span class="math inline">\(k\)</span>的假设集合<span class="math inline">\(\cal H\)</span>，给定<span class="math inline">\(m, \delta\)</span>，那么： <span class="math display">\[
\varepsilon(\hat h) \leq \underbrace{(\min_{h \in {\cal H}}\varepsilon(h))}_{\varepsilon(h^\ast)} + 2 \underbrace{\sqrt{\frac{1}{2m}log(\frac{2k}{\delta})}}_{\gamma}
\]</span> 的概率不低于<span class="math inline">\(1-\delta\)</span>。</p>
<p>可以想象，为了得到最佳的假设<span class="math inline">\(h^\ast\)</span>，我们尽可能增大<span class="math inline">\(\cal H\)</span>（能够减小<span class="math inline">\(\varepsilon(h^\ast)\)</span>），但随之而来的就是<span class="math inline">\(\gamma\)</span>的增大，所以需要在这两者之间进行权衡，我们指的就是<strong>偏差方差权衡 Bias Variance Tradeoff</strong>。</p>
<figure>
<img src="http://jackie-image.oss-cn-hangzhou.aliyuncs.com/19-01-06/image-20190106154201189.png" alt="image-20190106154201189"><figcaption>image-20190106154201189</figcaption>
</figure>
<p>由此，我们得到一个推论：</p>
<p>给定<span class="math inline">\(\delta, \gamma\)</span>，为了能够保证<span class="math inline">\(\varepsilon(\hat h) \leq (\min_{h \in {\cal H}}\varepsilon(h)) + 2\gamma\)</span>的概率不小于<span class="math inline">\(1-\delta\)</span>（ERM得到的假设的一般误差，与最佳假设的一般误差之间，差值不大于<span class="math inline">\(2\gamma\)</span>）</p>
<p>我们需要保证： <span class="math display">\[
m \geq \frac{1}{2\gamma^2}log(\frac{2k}{\delta})
\]</span></p>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
        <a href="/wiki/2019/01/10/吴恩达·机器学习/15-Vapnik-Chervonenkis Dimension/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Newer</strong>
            <div class="article-nav-title">
                
                    Vapnik–Chervonenkis dimension
                
            </div>
        </a>
    
    
        <a href="/wiki/2018/07/25/吴恩达·机器学习/13-SVM（四）非线性决策边界/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">SVM（四）非线性决策边界</div>
        </a>
    
</nav>





    
    




<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            Jiacheng Pan &copy; 2019 
            <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png"></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        

    
        <script src="/wiki/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/wiki/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/wiki/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/wiki/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/wiki/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/wiki/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/wiki/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/wiki/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/wiki/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/wiki/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->
<script src="/wiki/js/main.js"></script>

    </div>
</body>
</html>